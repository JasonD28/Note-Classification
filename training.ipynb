{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could Not Find c:\\Users\\Jason\\PycharmProjects\\NoteClassification\\logs\n"
     ]
    }
   ],
   "source": [
    "!del .\\logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs\\\\hparam_tuning\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data.npy\")\n",
    "labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_size = int(data.shape[0] * 0.85)\n",
    "test_dataset_size = data.shape[0] - train_dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.shuffle(data.shape[0])\n",
    "\n",
    "train_dataset = dataset.take(train_dataset_size)\n",
    "test_dataset = dataset.skip(train_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ShuffleDataset shapes: ((1025, 173, 3), ()), types: (tf.complex128, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_CONV_KERNEL_SIZE = hp.HParam(\"conv_kernel_size\", hp.Discrete([3, 5]))\n",
    "HP_POOL_STRIDE_SIZE = hp.HParam(\"pool_stride_size\", hp.Discrete([2, 6]))\n",
    "HP_POOL_WINDOW_SIZE = hp.HParam(\"pool_window_size\", hp.Discrete([2, 6]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "HP_DENSE_SIZE = hp.HParam(\"dense_size\", hp.Discrete([100, 500]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_EPOCH_SIZE = hp.HParam(\"epoch_size\", hp.Discrete([50, 400]))\n",
    "HP_BATCH_SIZE = hp.HParam(\"batch_sizes\", hp.Discrete([16, 64]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "CATEGORICAL_ACCURACY = \"categorical_crossentropy_accuracy\"\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_CONV_KERNEL_SIZE, HP_POOL_STRIDE_SIZE, HP_POOL_WINDOW_SIZE, HP_DROPOUT, HP_DENSE_SIZE, HP_OPTIMIZER, HP_EPOCH_SIZE, HP_BATCH_SIZE],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy'), hp.Metric(CATEGORICAL_ACCURACY, display_name='Cross-Entropy Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "  model = Sequential(\n",
    "    [\n",
    "        Conv2D(hparams[HP_NUM_UNITS], int(hparams[HP_CONV_KERNEL_SIZE]), padding=\"same\", activation=\"relu\", input_shape=(1025, 173, 3)),\n",
    "        MaxPooling2D(int(hparams[HP_POOL_WINDOW_SIZE]), strides= int(hparams[HP_POOL_STRIDE_SIZE])),\n",
    "        Conv2D(32, int(hparams[HP_CONV_KERNEL_SIZE]), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPooling2D(int(hparams[HP_POOL_WINDOW_SIZE]), strides= int(hparams[HP_POOL_STRIDE_SIZE])),\n",
    "        Conv2D(64, int(hparams[HP_CONV_KERNEL_SIZE]), padding=\"same\", activation=\"relu\"),\n",
    "        MaxPooling2D(int(hparams[HP_POOL_WINDOW_SIZE]), strides= int(hparams[HP_POOL_STRIDE_SIZE])),\n",
    "        Flatten(),\n",
    "        Dense(hparams[HP_DENSE_SIZE], activation=\"relu\"),\n",
    "        Dropout(hparams[HP_DROPOUT]),\n",
    "        Dense(65, activation=\"softmax\")\n",
    "    ]\n",
    "  )\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy', 'categorical_crossentropy_accuracy'],\n",
    "  )\n",
    "\n",
    "  model.fit(train_dataset,\n",
    "    batch_size=int(hparams[HP_BATCH_SIZE]),\n",
    "    epochs=int(hparams[HP_EPOCH_SIZE]),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "        hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "    ]\n",
    "  )\n",
    "  _, accuracy = model.evaluate(test_dataset)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "models = dict()\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        for epoch_size in np.linspace(HP_EPOCH_SIZE.domain.values[0], HP_EPOCH_SIZE.domain.values[1], 3):\n",
    "            for batch_size in np.linspace(HP_BATCH_SIZE.domain.values[0], HP_BATCH_SIZE.domain.values[1], 4):\n",
    "                for kernel_size in np.linspace(HP_CONV_KERNEL_SIZE.domain.values[0], HP_CONV_KERNEL_SIZE.domain.values[1], 3):\n",
    "                    for stride_size in np.linspace(HP_POOL_STRIDE_SIZE.domain.values[0], HP_POOL_STRIDE_SIZE.domain.values[1], 5):\n",
    "                        for window_size in np.linspace(HP_POOL_WINDOW_SIZE.domain.values[0], HP_POOL_WINDOW_SIZE.domain.values[1], 5):\n",
    "                            for dropout_rate in np.linspace(HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value, 2):\n",
    "                                for dense_size in np.linspace(HP_DENSE_SIZE.domain.values[0], HP_DENSE_SIZE.domain.values[1], 5):\n",
    "                                    hparams = {\n",
    "                                        HP_NUM_UNITS: num_units,\n",
    "                                        HP_DROPOUT: dropout_rate,\n",
    "                                        HP_OPTIMIZER: optimizer,\n",
    "                                        HP_EPOCH_SIZE: epoch_size,\n",
    "                                        HP_BATCH_SIZE: batch_size,\n",
    "                                        HP_CONV_KERNEL_SIZE: kernel_size,\n",
    "                                        HP_POOL_STRIDE_SIZE: stride_size,\n",
    "                                        HP_POOL_WINDOW_SIZE: window_size,\n",
    "                                        HP_DENSE_SIZE: dense_size,\n",
    "                                    }\n",
    "                                    run_name = \"run-%d\" % session_num\n",
    "                                    print('--- Starting trial: %s' % run_name)\n",
    "                                    print({h.name: hparams[h] for h in hparams})\n",
    "                                    train_test_model(hparams)\n",
    "                                    session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "443f26d540b6f43d30f5d1cb7c2a06f8c2881272fe959514b3f333f79c6ef059"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
